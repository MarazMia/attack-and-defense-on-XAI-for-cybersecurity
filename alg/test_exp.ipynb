{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing purpose ##\n",
    "import numpy as np\n",
    "import shap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from explainer import Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Create synthetic data\n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(100, 5)  # 100 samples, 5 features\n",
    "    y = (X.sum(axis=1) > 2.5).astype(int)  # Binary target\n",
    "    \n",
    "    # Test 1: Tree model (Random Forest)\n",
    "    print(\"Testing Tree Model Explainer...\")\n",
    "    rf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    tree_explainer = shap.TreeExplainer(rf, X, model_output=\"probability\")\n",
    "    sv_tree = tree_explainer.shap_values(X[:5])\n",
    "    print(\"Tree SHAP values (first 5 samples):\")\n",
    "    print(sv_tree[1])  # Show SHAP values for class 1\n",
    "    \n",
    "    # Test 2: Linear model (Logistic Regression)\n",
    "    print(\"\\nTesting Linear Model Explainer...\")\n",
    "    lr = LogisticRegression(random_state=42)\n",
    "    lr.fit(X, y)\n",
    "    \n",
    "    linear_explainer = shap.LinearExplainer(lr, X)\n",
    "    sv_linear = linear_explainer.shap_values(X[:5])\n",
    "    print(\"\\nLinear SHAP values (first 5 samples):\")\n",
    "    print(sv_linear)\n",
    "    \n",
    "    # Test 3: Neural Network (MLP Classifier)\n",
    "    print(\"\\nTesting Deep Model Explainer (MLP)...\")\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=500, random_state=42)\n",
    "    mlp.fit(X, y)\n",
    "    \n",
    "    # Create a prediction function that outputs probabilities\n",
    "    def mlp_predict(x):\n",
    "        return mlp.predict_proba(x)\n",
    "    \n",
    "    # Use KernelExplainer for MLP (more stable than DeepExplainer for scikit-learn MLP)\n",
    "    mlp_explainer = shap.KernelExplainer(mlp_predict, X[:50])  # Use 50 samples as background\n",
    "    sv_mlp = mlp_explainer.shap_values(X[:5])\n",
    "    print(\"\\nMLP SHAP values (first 5 samples):\")\n",
    "    print(sv_mlp[1])  # Show SHAP values for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Tree Model Explainer...\n",
      "Tree SHAP values (first 5 samples):\n",
      "[[ 0.01561667  0.38020001  0.12336667  0.05436667 -0.07855   ]\n",
      " [-0.0921     -0.30051667  0.05365    -0.05251667 -0.01351667]\n",
      " [-0.29260001  0.1224      0.0289     -0.17393334 -0.18976667]\n",
      " [-0.05565    -0.1649     -0.01448333 -0.06565    -0.10431667]\n",
      " [-0.02661667 -0.14653334 -0.1012     -0.08978334 -0.04086667]]\n",
      "\n",
      "Testing Linear Model Explainer...\n",
      "\n",
      "Linear SHAP values (first 5 samples):\n",
      "[[-0.1924061   0.78927122  0.60062715  0.13671834 -0.68476611]\n",
      " [-0.51543996 -0.86656322  0.9305281   0.14105727  0.58423175]\n",
      " [-0.71559052  0.82487905  0.84759076 -0.54563289 -0.62544551]\n",
      " [-0.47492506 -0.40993772  0.09111211 -0.15774564 -0.37395982]\n",
      " [ 0.15836766 -0.7155468  -0.48078824 -0.2735844   0.00495728]]\n",
      "\n",
      "Testing Deep Model Explainer (MLP)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df571c4f7c4246f8a9a4be7625ac7dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP SHAP values (first 5 samples):\n",
      "[[-0.01816745  0.11344995  0.10312167  0.02988169 -0.11838843]\n",
      " [-0.06022757 -0.10547729  0.14888789  0.02740122  0.1031561 ]\n",
      " [-0.0760021   0.11141031  0.13705339 -0.06066243 -0.11150012]\n",
      " [-0.05369936 -0.04481844  0.00187594 -0.01120245 -0.07402276]\n",
      " [ 0.02018443 -0.08256092 -0.10043595 -0.02673163 -0.00262634]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
