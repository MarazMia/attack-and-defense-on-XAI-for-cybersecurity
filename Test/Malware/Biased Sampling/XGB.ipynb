{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796b59a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def add_to_sys_path(relative_path):\n",
    "    abs_path = os.path.abspath(os.path.join(os.getcwd(), relative_path))\n",
    "    if abs_path not in sys.path:\n",
    "        sys.path.append(abs_path)\n",
    "\n",
    "add_to_sys_path(os.path.join('..', '..', '..', 'Utils'))\n",
    "add_to_sys_path(os.path.join('..', '..', '..', 'Model'))\n",
    "add_to_sys_path(os.path.join('..', '..', '..', 'Biased Sampling'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf27fbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from XGB import base_model as base_model_call\n",
    "from model_data_processing import Data_Handler, Model_Metrics_Visualizer\n",
    "from stealthy_sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d108af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SizeOfOptionalHeader</th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>MajorLinkerVersion</th>\n",
       "      <th>MinorLinkerVersion</th>\n",
       "      <th>SizeOfCode</th>\n",
       "      <th>SizeOfInitializedData</th>\n",
       "      <th>SizeOfUninitializedData</th>\n",
       "      <th>AddressOfEntryPoint</th>\n",
       "      <th>BaseOfCode</th>\n",
       "      <th>BaseOfData</th>\n",
       "      <th>...</th>\n",
       "      <th>ResourcesNb</th>\n",
       "      <th>ResourcesMeanEntropy</th>\n",
       "      <th>ResourcesMinEntropy</th>\n",
       "      <th>ResourcesMaxEntropy</th>\n",
       "      <th>ResourcesMeanSize</th>\n",
       "      <th>ResourcesMinSize</th>\n",
       "      <th>ResourcesMaxSize</th>\n",
       "      <th>LoadConfigurationSize</th>\n",
       "      <th>VersionInformationSize</th>\n",
       "      <th>legitimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>224</td>\n",
       "      <td>8450</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16896</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>16947</td>\n",
       "      <td>4096</td>\n",
       "      <td>24576</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.492126</td>\n",
       "      <td>3.492126</td>\n",
       "      <td>3.492126</td>\n",
       "      <td>864.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>864</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224</td>\n",
       "      <td>258</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>84480</td>\n",
       "      <td>25600</td>\n",
       "      <td>0</td>\n",
       "      <td>10973</td>\n",
       "      <td>4096</td>\n",
       "      <td>90112</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.486827</td>\n",
       "      <td>3.486827</td>\n",
       "      <td>3.486827</td>\n",
       "      <td>892.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>892</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224</td>\n",
       "      <td>8450</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4608</td>\n",
       "      <td>3584</td>\n",
       "      <td>0</td>\n",
       "      <td>6452</td>\n",
       "      <td>4096</td>\n",
       "      <td>12288</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.517270</td>\n",
       "      <td>3.517270</td>\n",
       "      <td>3.517270</td>\n",
       "      <td>952.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>952</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>224</td>\n",
       "      <td>8450</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>108544</td>\n",
       "      <td>15872</td>\n",
       "      <td>0</td>\n",
       "      <td>105021</td>\n",
       "      <td>4096</td>\n",
       "      <td>114688</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.270559</td>\n",
       "      <td>3.034188</td>\n",
       "      <td>3.506931</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>1092</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>224</td>\n",
       "      <td>8226</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>513024</td>\n",
       "      <td>2048</td>\n",
       "      <td>0</td>\n",
       "      <td>520922</td>\n",
       "      <td>8192</td>\n",
       "      <td>524288</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.420977</td>\n",
       "      <td>3.420977</td>\n",
       "      <td>3.420977</td>\n",
       "      <td>954.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SizeOfOptionalHeader  Characteristics  MajorLinkerVersion  \\\n",
       "0                   224             8450                 8.0   \n",
       "1                   224              258                 9.0   \n",
       "2                   224             8450                 8.0   \n",
       "3                   224             8450                10.0   \n",
       "4                   224             8226                48.0   \n",
       "\n",
       "   MinorLinkerVersion  SizeOfCode  SizeOfInitializedData  \\\n",
       "0                   0       16896                   8192   \n",
       "1                   0       84480                  25600   \n",
       "2                   0        4608                   3584   \n",
       "3                   0      108544                  15872   \n",
       "4                   0      513024                   2048   \n",
       "\n",
       "   SizeOfUninitializedData  AddressOfEntryPoint  BaseOfCode  BaseOfData  ...  \\\n",
       "0                        0                16947        4096       24576  ...   \n",
       "1                        0                10973        4096       90112  ...   \n",
       "2                        0                 6452        4096       12288  ...   \n",
       "3                        0               105021        4096      114688  ...   \n",
       "4                        0               520922        8192      524288  ...   \n",
       "\n",
       "   ResourcesNb  ResourcesMeanEntropy  ResourcesMinEntropy  \\\n",
       "0            1              3.492126             3.492126   \n",
       "1            1              3.486827             3.486827   \n",
       "2            1              3.517270             3.517270   \n",
       "3            2              3.270559             3.034188   \n",
       "4            1              3.420977             3.420977   \n",
       "\n",
       "   ResourcesMaxEntropy  ResourcesMeanSize  ResourcesMinSize  ResourcesMaxSize  \\\n",
       "0             3.492126              864.0             864.0               864   \n",
       "1             3.486827              892.0             892.0               892   \n",
       "2             3.517270              952.0             952.0               952   \n",
       "3             3.506931             1032.0             972.0              1092   \n",
       "4             3.420977              954.0             954.0               954   \n",
       "\n",
       "   LoadConfigurationSize  VersionInformationSize  legitimate  \n",
       "0                     72                       0           1  \n",
       "1                     72                       0           1  \n",
       "2                     72                       0           1  \n",
       "3                     72                       0           1  \n",
       "4                      0                       0           1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../../Dataset/Kaggle-data.csv')\n",
    "data = data.drop(data.select_dtypes(include='object').columns, axis=1)\n",
    "data = data.drop(columns=['ID', 'Unnamed: 57'])\n",
    "protected_feature = 'Subsystem'\n",
    "\n",
    "data = data.dropna(axis=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07260bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying feature correlation removal...\n",
      "Scaling only continuous numerical features (excluding heuristic categoricals and protected feature by default).\n",
      "Features actually being scaled: ['SizeOfOptionalHeader', 'Characteristics', 'MajorLinkerVersion', 'SizeOfCode', 'SizeOfInitializedData', 'SizeOfUninitializedData', 'AddressOfEntryPoint', 'BaseOfCode', 'ImageBase', 'SectionAlignment', 'FileAlignment', 'MajorOperatingSystemVersion', 'MajorImageVersion', 'MajorSubsystemVersion', 'MinorSubsystemVersion', 'SizeOfHeaders', 'CheckSum', 'SizeOfStackReserve', 'SectionsNb', 'SectionsMeanRawsize', 'SectionsMinRawsize', 'ImportsNb', 'ExportNb', 'ResourcesNb', 'ResourcesMeanEntropy', 'ResourcesMeanSize', 'LoadConfigurationSize', 'VersionInformationSize']\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, feature_names, scaler = Data_Handler(\n",
    "        df=data,\n",
    "        target_column='legitimate',\n",
    "        protected_feature=protected_feature,\n",
    "        do_scaling=True,\n",
    "        correlation_threshold=0.35,\n",
    "        test_size=0.3,\n",
    "        random_state=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03db8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SizeOfOptionalHeader</th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>MajorLinkerVersion</th>\n",
       "      <th>SizeOfCode</th>\n",
       "      <th>SizeOfInitializedData</th>\n",
       "      <th>SizeOfUninitializedData</th>\n",
       "      <th>AddressOfEntryPoint</th>\n",
       "      <th>BaseOfCode</th>\n",
       "      <th>ImageBase</th>\n",
       "      <th>SectionAlignment</th>\n",
       "      <th>...</th>\n",
       "      <th>SectionsNb</th>\n",
       "      <th>SectionsMeanRawsize</th>\n",
       "      <th>SectionsMinRawsize</th>\n",
       "      <th>ImportsNb</th>\n",
       "      <th>ExportNb</th>\n",
       "      <th>ResourcesNb</th>\n",
       "      <th>ResourcesMeanEntropy</th>\n",
       "      <th>ResourcesMeanSize</th>\n",
       "      <th>LoadConfigurationSize</th>\n",
       "      <th>VersionInformationSize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23720</th>\n",
       "      <td>-0.305154</td>\n",
       "      <td>0.485687</td>\n",
       "      <td>0.033611</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>-0.019331</td>\n",
       "      <td>-0.017655</td>\n",
       "      <td>-0.011831</td>\n",
       "      <td>-0.008912</td>\n",
       "      <td>-0.005751</td>\n",
       "      <td>-0.006757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038719</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>-0.059186</td>\n",
       "      <td>-0.146148</td>\n",
       "      <td>-0.079959</td>\n",
       "      <td>-0.151470</td>\n",
       "      <td>-0.200632</td>\n",
       "      <td>-0.007894</td>\n",
       "      <td>-0.020052</td>\n",
       "      <td>-0.977947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76198</th>\n",
       "      <td>-0.305154</td>\n",
       "      <td>-0.559387</td>\n",
       "      <td>-0.036640</td>\n",
       "      <td>-0.019715</td>\n",
       "      <td>-0.015673</td>\n",
       "      <td>-0.017626</td>\n",
       "      <td>-0.019790</td>\n",
       "      <td>-0.008912</td>\n",
       "      <td>-0.005751</td>\n",
       "      <td>-0.006757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038719</td>\n",
       "      <td>-0.021930</td>\n",
       "      <td>-0.060777</td>\n",
       "      <td>0.380521</td>\n",
       "      <td>-0.091228</td>\n",
       "      <td>-0.062156</td>\n",
       "      <td>0.788055</td>\n",
       "      <td>-0.006975</td>\n",
       "      <td>-0.020054</td>\n",
       "      <td>-0.977947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26039</th>\n",
       "      <td>-0.305154</td>\n",
       "      <td>-0.561048</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>-0.020603</td>\n",
       "      <td>-0.019977</td>\n",
       "      <td>-0.017648</td>\n",
       "      <td>-0.019970</td>\n",
       "      <td>-0.008912</td>\n",
       "      <td>-0.005751</td>\n",
       "      <td>-0.006757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437017</td>\n",
       "      <td>-0.024194</td>\n",
       "      <td>-0.060777</td>\n",
       "      <td>-0.292445</td>\n",
       "      <td>-0.091228</td>\n",
       "      <td>-0.144027</td>\n",
       "      <td>0.389231</td>\n",
       "      <td>-0.007935</td>\n",
       "      <td>-0.020052</td>\n",
       "      <td>-0.977947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201594</th>\n",
       "      <td>-0.305154</td>\n",
       "      <td>-0.561048</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>-0.019520</td>\n",
       "      <td>-0.005840</td>\n",
       "      <td>-0.017419</td>\n",
       "      <td>-0.019684</td>\n",
       "      <td>-0.008912</td>\n",
       "      <td>-0.005751</td>\n",
       "      <td>-0.006757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437017</td>\n",
       "      <td>-0.020145</td>\n",
       "      <td>-0.060777</td>\n",
       "      <td>0.424410</td>\n",
       "      <td>-0.091228</td>\n",
       "      <td>-0.002613</td>\n",
       "      <td>-0.255934</td>\n",
       "      <td>-0.006457</td>\n",
       "      <td>-0.020054</td>\n",
       "      <td>-0.977947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211321</th>\n",
       "      <td>-0.305154</td>\n",
       "      <td>-0.561048</td>\n",
       "      <td>0.010194</td>\n",
       "      <td>-0.014633</td>\n",
       "      <td>-0.007843</td>\n",
       "      <td>-0.017655</td>\n",
       "      <td>-0.016655</td>\n",
       "      <td>-0.008912</td>\n",
       "      <td>-0.005751</td>\n",
       "      <td>-0.006757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038719</td>\n",
       "      <td>-0.009999</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>-0.091228</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>2.330882</td>\n",
       "      <td>-0.004251</td>\n",
       "      <td>-0.020053</td>\n",
       "      <td>0.762113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SizeOfOptionalHeader  Characteristics  MajorLinkerVersion  SizeOfCode  \\\n",
       "23720              -0.305154         0.485687            0.033611   -0.004386   \n",
       "76198              -0.305154        -0.559387           -0.036640   -0.019715   \n",
       "26039              -0.305154        -0.561048            0.021903   -0.020603   \n",
       "201594             -0.305154        -0.561048            0.010194   -0.019520   \n",
       "211321             -0.305154        -0.561048            0.010194   -0.014633   \n",
       "\n",
       "        SizeOfInitializedData  SizeOfUninitializedData  AddressOfEntryPoint  \\\n",
       "23720               -0.019331                -0.017655            -0.011831   \n",
       "76198               -0.015673                -0.017626            -0.019790   \n",
       "26039               -0.019977                -0.017648            -0.019970   \n",
       "201594              -0.005840                -0.017419            -0.019684   \n",
       "211321              -0.007843                -0.017655            -0.016655   \n",
       "\n",
       "        BaseOfCode  ImageBase  SectionAlignment  ...  SectionsNb  \\\n",
       "23720    -0.008912  -0.005751         -0.006757  ...    0.038719   \n",
       "76198    -0.008912  -0.005751         -0.006757  ...    0.038719   \n",
       "26039    -0.008912  -0.005751         -0.006757  ...    0.437017   \n",
       "201594   -0.008912  -0.005751         -0.006757  ...    0.437017   \n",
       "211321   -0.008912  -0.005751         -0.006757  ...    0.038719   \n",
       "\n",
       "        SectionsMeanRawsize  SectionsMinRawsize  ImportsNb  ExportNb  \\\n",
       "23720             -0.014858           -0.059186  -0.146148 -0.079959   \n",
       "76198             -0.021930           -0.060777   0.380521 -0.091228   \n",
       "26039             -0.024194           -0.060777  -0.292445 -0.091228   \n",
       "201594            -0.020145           -0.060777   0.424410 -0.091228   \n",
       "211321            -0.009999           -0.030535   0.007464 -0.091228   \n",
       "\n",
       "        ResourcesNb  ResourcesMeanEntropy  ResourcesMeanSize  \\\n",
       "23720     -0.151470             -0.200632          -0.007894   \n",
       "76198     -0.062156              0.788055          -0.006975   \n",
       "26039     -0.144027              0.389231          -0.007935   \n",
       "201594    -0.002613             -0.255934          -0.006457   \n",
       "211321     0.004829              2.330882          -0.004251   \n",
       "\n",
       "        LoadConfigurationSize  VersionInformationSize  \n",
       "23720               -0.020052               -0.977947  \n",
       "76198               -0.020054               -0.977947  \n",
       "26039               -0.020052               -0.977947  \n",
       "201594              -0.020054               -0.977947  \n",
       "211321              -0.020053                0.762113  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x_train.columns))\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "930be58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9722675869719286\n",
      "Precision: 0.9722288758935483\n",
      "Recall: 0.9722675869719286\n",
      "F-1: 0.9722361767935748\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = base_model_call(x_train, y_train, protected_feature, True)\n",
    "y_pred = model.predict(x_test)\n",
    "Model_Metrics_Visualizer(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the DataFrame to the attacker class to maintain feature names for plotting\n",
    "attacker = AdversarialSHAPBackgroundAttack(\n",
    "        model=model,\n",
    "        X_train=x_train,\n",
    "        sensitive_feature_name=protected_feature,\n",
    "        sensitive_feature_index=list(x_train.columns).index(protected_feature),\n",
    "        explainer_type='kernel',\n",
    "        background_size=200,\n",
    "        lambda_reg=1e-4,\n",
    "        gamma_entropy=1e-7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c3858d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running attack with TreeExplainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:58:50] WARNING: C:\\b\\abs_0fh_d4x2ng\\croot\\xgboost-split_1713973188995\\work\\cpp_src\\src\\c_api\\c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n"
     ]
    },
    {
     "ename": "ExplainerError",
     "evalue": "Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was -4.007535, while the model output was -4.005844. If this difference is acceptable you can set check_additivity=False to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExplainerError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m biased_weights, before, after \u001b[38;5;241m=\u001b[39m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m attacker\u001b[38;5;241m.\u001b[39mplot_shap_comparison(before, after)\n",
      "File \u001b[1;32mc:\\Users\\mmia43\\Desktop\\Adversarial_Attack_On_XAI\\Biased Sampling\\stealthy_sampling.py:150\u001b[0m, in \u001b[0;36mAdversarialSHAPBackgroundAttack.run_attack\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    147\u001b[0m background_for_explainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackground_set\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackground_set)), random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m    148\u001b[0m explainer_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_explainer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, background\u001b[38;5;241m=\u001b[39mbackground_for_explainer)\n\u001b[1;32m--> 150\u001b[0m shap_values_before \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_shap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexplainer_before\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackground_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m mean_shap_before \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(shap_values_before, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Before] Mean SHAP per feature:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmean_shap_before\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mmia43\\Desktop\\Adversarial_Attack_On_XAI\\Biased Sampling\\stealthy_sampling.py:105\u001b[0m, in \u001b[0;36mAdversarialSHAPBackgroundAttack._get_shap_values\u001b[1;34m(self, explainer, data, nsamples)\u001b[0m\n\u001b[0;32m    103\u001b[0m         shap_vals \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(data, nsamples\u001b[38;5;241m=\u001b[39mnsamples)\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m         shap_vals \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shap_vals, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m shap_vals[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mmia43\\.conda\\envs\\Pytorch\\lib\\site-packages\\shap\\explainers\\_tree.py:442\u001b[0m, in \u001b[0;36mTree.shap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    440\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_shap_output(phi, flat_output)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_additivity \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_additivity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\mmia43\\.conda\\envs\\Pytorch\\lib\\site-packages\\shap\\explainers\\_tree.py:575\u001b[0m, in \u001b[0;36mTree.assert_additivity\u001b[1;34m(self, phi, model_output)\u001b[0m\n\u001b[0;32m    573\u001b[0m         check_sum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value[i] \u001b[38;5;241m+\u001b[39m phi[i]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), model_output[:,i])\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 575\u001b[0m     \u001b[43mcheck_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpected_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mmia43\\.conda\\envs\\Pytorch\\lib\\site-packages\\shap\\explainers\\_tree.py:569\u001b[0m, in \u001b[0;36mTree.assert_additivity.<locals>.check_sum\u001b[1;34m(sum_val, model_output)\u001b[0m\n\u001b[0;32m    565\u001b[0m     err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Consider retrying with the feature_perturbation=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterventional\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m option.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This check failed because for one of the samples the sum of the SHAP values\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    567\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m was \u001b[39m\u001b[38;5;132;01m{:f}\u001b[39;00m\u001b[38;5;124m, while the model output was \u001b[39m\u001b[38;5;132;01m{:f}\u001b[39;00m\u001b[38;5;124m. If this difference is acceptable\u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    568\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m you can set check_additivity=False to disable this check.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(sum_val[ind], model_output[ind])\n\u001b[1;32m--> 569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExplainerError(err_msg)\n",
      "\u001b[1;31mExplainerError\u001b[0m: Additivity check failed in TreeExplainer! Please ensure the data matrix you passed to the explainer is the same shape that the model was trained on. If your data shape is correct then please report this on GitHub. This check failed because for one of the samples the sum of the SHAP values was -4.007535, while the model output was -4.005844. If this difference is acceptable you can set check_additivity=False to disable this check."
     ]
    }
   ],
   "source": [
    "biased_weights, before, after = attacker.run_attack()\n",
    "attacker.plot_shap_comparison(before, after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3aeef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive feature 'has_failed_logins' importance before attack: -0.0003\n",
      "Sensitive feature 'has_failed_logins' importance after attack: -0.0018\n",
      "Change in importance: -0.0015 (540.36%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sensitive feature '{protected_feature}' importance before attack: {before[attacker.sensitive_feature_index]:.4f}\")\n",
    "print(f\"Sensitive feature '{protected_feature}' importance after attack: {after[attacker.sensitive_feature_index]:.4f}\")\n",
    "    \n",
    "change = after[attacker.sensitive_feature_index] - before[attacker.sensitive_feature_index]\n",
    "pct_change = (change / before[attacker.sensitive_feature_index] * 100) if before[attacker.sensitive_feature_index] != 0 else float('inf')\n",
    "print(f\"Change in importance: {change:.4f} ({pct_change:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
